{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# New Clustering of Breast Cancer Subtypes Using Gene Expression Data and the BIGCLAM Method\n",
        "_(Training BIGCLAM(GPU) model on breast cancer gene expression data)_\n"
      ],
      "metadata": {
        "id": "9kdkzPFeWj2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Import Necessary Libraries"
      ],
      "metadata": {
        "id": "5y9CfdC9WlVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation and utilities\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Graphs and visualization\n",
        "import networkx as nx\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning and preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    matthews_corrcoef,\n",
        ")"
      ],
      "metadata": {
        "id": "eM-hvAUMWmAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Data Prepration"
      ],
      "metadata": {
        "id": "8LxAvfi-WuXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìÇ Load the dataset"
      ],
      "metadata": {
        "id": "oJzK0cRUXRTB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N69CfpIWl8Io"
      },
      "outputs": [],
      "source": [
        "# PAM50 column from clinical dataset has been added to genomic dataset as target\n",
        "df = pd.read_csv('/content/drive/MyDrive/gene_expression_data_target_added.csv')\n",
        "\n",
        "#making columns as features\n",
        "data = df.T\n",
        "\n",
        "#removing PAM50 column from dataset\n",
        "X = data.iloc[1:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPUekdLThP-"
      },
      "source": [
        "### Feature Reduction(Variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDtT_SOol9Hc"
      },
      "outputs": [],
      "source": [
        "indices_names = data.iloc[0, :-1]  # Get the names of the indices from the first row\n",
        "\n",
        "# Initialize the VarianceThreshold object(threshold=13 founded through trial and errors)\n",
        "var_threshold = VarianceThreshold(threshold=13)\n",
        "\n",
        "# Fit the VarianceThreshold to data\n",
        "var_threshold.fit(X)\n",
        "\n",
        "# Get the indices of the features to keep\n",
        "selected_features = var_threshold.get_support(indices=True)\n",
        "\n",
        "# Extract the names of the selected features using the first row of 'data'\n",
        "selected_feature_names = indices_names.iloc[selected_features].values\n",
        "\n",
        "# Create a DataFrame to display the selected feature indices and their corresponding names\n",
        "df_selected_features = pd.DataFrame({\n",
        "    \"Selected Feature Index\": selected_features,\n",
        "    \"Feature Name\": selected_feature_names\n",
        "})\n",
        "\n",
        "# Export the DataFrame to an Excel file\n",
        "#df_selected_features.to_excel(\"selected_features_with_names.xlsx\", index=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Selected features have been exported to 'selected_features_with_names.xlsx'\")\n",
        "\n",
        "# Subset the original data with the selected features\n",
        "X_reduced = X.iloc[:, selected_features]\n",
        "# X_reduced = pd.concat([X_reduced,data.iloc[1: , -1]],axis = 1)\n",
        "# Check the shape of the reduced data\n",
        "print(\"Original data shape:\", X.shape)\n",
        "print(\"Reduced data shape:\", X_reduced.shape)\n",
        "print(X_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Md8KRtrUARu"
      },
      "source": [
        "##  Graph Making"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEsbFdVRBVBk",
        "outputId": "12fb3c5f-cfbc-4341-da63-71896a599d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved to Google Drive at: /content/drive/MyDrive/TCGA/\n"
          ]
        }
      ],
      "source": [
        "def create_adjacency_and_assignments(df, threshold=0.4):\n",
        "    N = df.shape[0]\n",
        "    num_features = df.shape[1] - 1  # last column is community\n",
        "\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "    features = df.iloc[:, :num_features].values\n",
        "    similarity_matrix = cosine_similarity(features)\n",
        "\n",
        "    A = (similarity_matrix > threshold).astype(int) - np.eye(N).astype(int)\n",
        "\n",
        "    community_assignments = df.iloc[:, -1].apply(lambda x: {int(x)}).tolist()\n",
        "\n",
        "    return A, community_assignments\n",
        "\n",
        "def gen_json(A, p2c, F_argmax=None):\n",
        "    N = A.shape[0]\n",
        "    data = {'nodes':[], 'links':[]}\n",
        "\n",
        "    for i in range(N):\n",
        "        grp = ''.join(map(str, sorted(p2c[i])))\n",
        "        node = {'id': str(i), 'group': str(grp)}\n",
        "        if F_argmax is not None:\n",
        "            node.update({'assigned': str(F_argmax[i])})\n",
        "        data['nodes'].append(node)\n",
        "        friends = np.where(A[i])\n",
        "        for friend in friends[0]:\n",
        "            inter = 2 - len(p2c[i].intersection(p2c[friend]))\n",
        "            data['links'].append({'source': str(i), 'target': str(friend), 'value': str(inter * 5 + 1), 'distance': str(inter * 15 + 1)})\n",
        "    return data\n",
        "\n",
        "# Load dataset\n",
        "df = X_reduced\n",
        "\n",
        "# Create adjacency matrix and community assignments\n",
        "A, p2c = create_adjacency_and_assignments(df)\n",
        "\n",
        "# Generate JSON data\n",
        "data = gen_json(A, p2c)\n",
        "\n",
        "# Save the data\n",
        "with open('data.json', 'w') as f:\n",
        "    json.dump(data, f, indent=4)\n",
        "\n",
        "# Define the path in your Google Drive where you want to save the files\n",
        "save_path = '/content/drive/MyDrive/BIGCLAM_data/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# Save the adjacency matrix and community assignments\n",
        "np.save(os.path.join(save_path, 'adj.npy'), A + A.T)\n",
        "pickle.dump(p2c, open(os.path.join(save_path, \"p2c.pkl\"), \"wb\"))\n",
        "\n",
        "print(f\"Files saved to Google Drive at: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CBYW9uGd2W1"
      },
      "source": [
        "## üöÄ Initialize the BIGCLAM Model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwEtnn5ld12R"
      },
      "outputs": [],
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def sigm(x):\n",
        "    return torch.div(torch.exp(-1. * x), 1. - torch.exp(-1. * x))\n",
        "\n",
        "def log_likelihood(F, A):\n",
        "    A_soft = F @ F.T  # Matrix multiplication in PyTorch\n",
        "    FIRST_PART = A * torch.log(1. - torch.exp(-1. * A_soft))\n",
        "    sum_edges = torch.sum(FIRST_PART)\n",
        "    SECOND_PART = (1 - A) * A_soft\n",
        "    sum_nedges = torch.sum(SECOND_PART)\n",
        "    log_likeli = sum_edges - sum_nedges\n",
        "    return log_likeli\n",
        "\n",
        "def gradient(F, A, i):\n",
        "    N, C = F.shape\n",
        "    neighbours = torch.where(A[i])[0]\n",
        "    nneighbours = torch.where(1 - A[i])[0]\n",
        "    sum_neigh = torch.zeros((C,), device=device)\n",
        "    for nb in neighbours:\n",
        "        dotproduct = F[nb].dot(F[i])\n",
        "        sum_neigh += F[nb] * sigm(dotproduct)\n",
        "    sum_nneigh = torch.zeros((C,), device=device)\n",
        "    for nnb in nneighbours:\n",
        "        sum_nneigh += F[nnb]\n",
        "    grad = sum_neigh - sum_nneigh\n",
        "    return grad\n",
        "\n",
        "def train(A, max_communities=10, iterations=100):\n",
        "    N = A.shape[0]\n",
        "    best_F = None\n",
        "    best_num_communities = 1\n",
        "    best_aic = float('inf')\n",
        "    for num_communities in range(1, max_communities + 1):\n",
        "        F = torch.rand((N, num_communities), device=device, requires_grad=True)\n",
        "        optimizer = torch.optim.Adam([F], lr=0.08)  # Use an optimizer for better convergence\n",
        "        for n in range(iterations):\n",
        "            optimizer.zero_grad()\n",
        "            ll = log_likelihood(F, A)\n",
        "            loss = -ll  # Minimize negative log-likelihood\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                F.data = torch.clamp(F.data, min=0.000000000001)  # Ensure F is nonnegative\n",
        "        # Calculate AIC\n",
        "        k = N * num_communities  # Number of parameters\n",
        "        aic = -2 * ll.item() + 2 * k\n",
        "        if aic < best_aic:\n",
        "            best_aic = aic\n",
        "            best_F = F.detach().cpu().numpy()  # Move back to CPU for compatibility\n",
        "            best_num_communities = num_communities\n",
        "        print(f'At step {num_communities}/{max_communities}, AIC: {aic}')\n",
        "    print(f\"Best number of communities: {best_num_communities}\")\n",
        "    return best_F\n",
        "\n",
        "def gen_json(A, p2c, F_argmax=None):\n",
        "    N = A.shape[0]\n",
        "    data = {'nodes': [], 'links': []}\n",
        "    for i in range(N):\n",
        "        grp = ''.join(map(str, sorted(p2c[i])))\n",
        "        node = {'id': str(i), 'group': str(grp)}\n",
        "        if F_argmax is not None:\n",
        "            node.update({'assigned': str(F_argmax[i])})\n",
        "        data['nodes'].append(node)\n",
        "        friends = torch.where(A[i])[0].cpu().numpy()  # Ensure A is a PyTorch tensor\n",
        "        for friend in friends:\n",
        "            inter = 2 - len(p2c[i].intersection(p2c[friend]))\n",
        "            data['links'].append({'source': str(i), 'target': str(friend), 'value': str(inter * 5 + 1), 'distance': str(inter * 15 + 1)})\n",
        "    return data\n",
        "\n",
        "def visualize_bipartite(F, p2c):\n",
        "    B = nx.Graph()\n",
        "    N, C = F.shape\n",
        "    person_nodes = [\"Person {}\".format(i) for i in range(N)]\n",
        "    community_nodes = [\"Community {}\".format(i) for i in range(C)]\n",
        "\n",
        "    B.add_nodes_from(person_nodes, bipartite=0)\n",
        "    B.add_nodes_from(community_nodes, bipartite=1)\n",
        "\n",
        "    for i, comm_prefs in enumerate(F):\n",
        "        for c, membership in enumerate(comm_prefs):\n",
        "            if membership > 0:\n",
        "                B.add_edge(person_nodes[i], community_nodes[c])\n",
        "\n",
        "    pos = nx.drawing.layout.bipartite_layout(B, person_nodes)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    nx.draw(B, pos, with_labels=True, node_color=['skyblue' if n in person_nodes else 'lightgreen' for n in B.nodes()], edge_color='gray')\n",
        "    plt.title('Bipartite Graph of People and Communities')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the path in your Google Drive where the files are saved\n",
        "    load_path = '/content/drive/MyDrive/BIGCLAM_data/'\n",
        "\n",
        "    # Load the adjacency matrix and community assignments\n",
        "    adj = np.load(os.path.join(load_path, 'adj.npy'))\n",
        "    p2c = pickle.load(open(os.path.join(load_path, 'p2c.pkl'), 'rb'))\n",
        "\n",
        "    # Convert adjacency matrix to a PyTorch tensor and move to GPU\n",
        "    adj = torch.tensor(adj, device=device)\n",
        "\n",
        "    # Number of communities (adjust this based on data)\n",
        "    num_communities = 4\n",
        "\n",
        "    # Train the BigClAM model\n",
        "    F = train(adj, num_communities)\n",
        "    F_argmax = np.argmax(F, 1)\n",
        "\n",
        "    # Generate the JSON data (pass adj as a tensor)\n",
        "    data = gen_json(adj, p2c, F_argmax)\n",
        "\n",
        "    # Save the generated JSON data\n",
        "    with open('data.json', 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "    # Optionally print the results\n",
        "    for i, row in enumerate(F):\n",
        "        print(f\"Person {i}: Community Preferences - {row}\")\n",
        "        print(f\"Person {i}: Assigned Communities - {p2c[i]}\")\n",
        "\n",
        "    # Visualize as a bipartite graph\n",
        "    visualize_bipartite(F, p2c)\n",
        "\n",
        "# Add the community labels as a new column to the dataframe\n",
        "df = X_reduced\n",
        "df['Community'] = F_argmax\n",
        "# Save the updated dataframe\n",
        "df.to_csv('/content/drive/MyDrive/reduced_data_BC_label.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## counts of each class from new clustered dataset"
      ],
      "metadata": {
        "id": "hvQvZTx6bmHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI1GdaGEkmNf"
      },
      "outputs": [],
      "source": [
        "# load the clustered dataset as X\n",
        "X = pd.read_csv('/content/drive/MyDrive/reduced_data_BC_label.csv')\n",
        "# counts of each class\n",
        "class_counts = X.iloc[:, -1].value_counts()\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTcJBB4fVjox"
      },
      "source": [
        "## Comparing PAM50 with new label per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbHia_sTte3j"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "data_with_community = pd.read_csv('/content/drive/MyDrive/reduced_data_BC_label.csv')\n",
        "\n",
        "# Upploading dataset containg PAM50 column as target\n",
        "data = pd.read_csv('/content/drive/MyDrive/gene_expression_data_target_added.csv')\n",
        "data = data.T\n",
        "data.iloc[:,-1] = data.iloc[:,-1].replace('pam50 subtype: Normal', 0)\n",
        "data.iloc[:,-1] = data.iloc[:,-1].replace('pam50 subtype: LumA', 1)\n",
        "data.iloc[:,-1] = data.iloc[:,-1].replace('pam50 subtype: LumB', 2)\n",
        "data.iloc[:,-1] = data.iloc[:,-1].replace('pam50 subtype: Her2', 3)\n",
        "data.iloc[:,-1] = data.iloc[:,-1].replace('pam50 subtype: Basal', 4)\n",
        "#data\n",
        "data = data[data.iloc[:, -1]!=0]\n",
        "label_data = data.iloc[1:,-1]\n",
        "label_data\n",
        "\n",
        "# Assign the labels to the last column of data_with_community\n",
        "data_with_community['label'] = label_data.values\n",
        "\n",
        "# Ensure the columns are named correctly\n",
        "if 'Community' not in data_with_community.columns:\n",
        "    data_with_community.rename(columns={data_with_community.columns[-2]: 'Community'}, inplace=True)\n",
        "if 'label' not in data_with_community.columns:\n",
        "    data_with_community.rename(columns={data_with_community.columns[-1]: 'label'}, inplace=True)\n",
        "\n",
        "# Count the number of each label in each community\n",
        "label_counts_per_community = data_with_community.groupby('Community')['label'].value_counts().unstack().fillna(0).astype(int)\n",
        "\n",
        "# Display the results\n",
        "for community, labels in label_counts_per_community.iterrows():\n",
        "    print(f\"Community {community}:\")\n",
        "    for label, count in labels.items():\n",
        "        print(f\"  class {int(label)}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîç Evaluate the model\n",
        "(training MLP and SVM models using BIGCLAM clusterd gene expression data)"
      ],
      "metadata": {
        "id": "xeWn0EpUc4XA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Preprocess the Data"
      ],
      "metadata": {
        "id": "b775f-AhdV38"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqet3QMEVZrm"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOqJIU2_erV4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Separate features and labels\n",
        "features = X.iloc[:, :-1].values\n",
        "labels = X.iloc[:, -1].values\n",
        "\n",
        "# Find the maximum number of samples among all classes\n",
        "max_samples = max(np.sum(labels == label) for label in set(labels))\n",
        "\n",
        "# Create a dictionary to store the indices of samples for each class\n",
        "class_indices = {label: np.where(labels == label)[0] for label in set(labels)}\n",
        "\n",
        "# Create an empty list to store augmented data\n",
        "augmented_data = []\n",
        "\n",
        "# Augment each class to reach the maximum number of samples\n",
        "for label, indices in class_indices.items():\n",
        "    # Calculate the number of augmentations needed for this class\n",
        "    num_augmentations = max_samples - len(indices)\n",
        "\n",
        "    # Randomly sample existing examples from this class\n",
        "    sampled_indices = np.random.choice(indices, num_augmentations, replace=True)\n",
        "\n",
        "    # Apply augmentations to each sampled example\n",
        "    for index in sampled_indices:\n",
        "        feature_row = features[index, :]\n",
        "\n",
        "        # Add random noise to the gene expression values\n",
        "        noise = np.random.normal(0, 0.1, feature_row.shape)\n",
        "        augmented_feature_row = feature_row + noise\n",
        "\n",
        "        augmented_data.append(np.concatenate([augmented_feature_row, [label]]))\n",
        "\n",
        "# Convert the augmented data to a DataFrame\n",
        "augmented_data = pd.DataFrame(augmented_data, columns=X.columns)\n",
        "\n",
        "# Concatenate the original and augmented data\n",
        "augmented_data = pd.concat([X, augmented_data], ignore_index=True)\n",
        "class_counts = augmented_data.iloc[:, -1].value_counts()\n",
        "print(\"Class counts in augmented_data:\\n\", class_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdKlE9maG17H"
      },
      "source": [
        "### ‚úÇÔ∏è Data Splitting and normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmEPdBWKFKif"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming `augmented_data` is your dataset and the last column is the class label\n",
        "# Example: augmented_data = pd.DataFrame(...)\n",
        "\n",
        "# Initialize empty DataFrames for train, validation, and test sets\n",
        "X_train = pd.DataFrame()\n",
        "X_valid = pd.DataFrame()\n",
        "X_test = pd.DataFrame()\n",
        "\n",
        "# Iterate over each class\n",
        "for class_label in augmented_data.iloc[:, -1].unique():\n",
        "    # Filter data for the current class\n",
        "    class_data = augmented_data[augmented_data.iloc[:, -1] == class_label]\n",
        "\n",
        "    # Calculate the number of samples for each split\n",
        "    total_samples = len(class_data)\n",
        "    test_size = int(0.2 * total_samples)  # 10% for test\n",
        "    valid_size = int(0.2 * total_samples)  # 10% for validation\n",
        "    train_size = total_samples - test_size - valid_size  # 80% for train\n",
        "\n",
        "    # Split the data\n",
        "    test_data = class_data.iloc[:test_size]  # First 10% for test\n",
        "    valid_data = class_data.iloc[test_size:test_size + valid_size]  # Next 10% for validation\n",
        "    train_data = class_data.iloc[test_size + valid_size:]  # Remaining 80% for train\n",
        "\n",
        "    # Append to the respective sets\n",
        "    X_test = pd.concat([X_test, test_data])\n",
        "    X_valid = pd.concat([X_valid, valid_data])\n",
        "    X_train = pd.concat([X_train, train_data])\n",
        "\n",
        "# Shuffle the datasets\n",
        "X_test = X_test.sample(frac=1).reset_index(drop=True)\n",
        "X_valid = X_valid.sample(frac=1).reset_index(drop=True)\n",
        "X_train = X_train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Verify the splits\n",
        "print(f'Test set size: {X_test.shape}')\n",
        "print(f'Validation set size: {X_valid.shape}')\n",
        "print(f'Train set size: {X_train.shape}')\n",
        "\n",
        "# Define feature columns and target column for each set\n",
        "y_train = X_train.iloc[:,-1]\n",
        "y_valid = X_valid.iloc[:,-1]\n",
        "y_test = X_test.iloc[:,-1]\n",
        "\n",
        "X_train = X_train.iloc[:,:-1]\n",
        "X_valid = X_valid.iloc[:,:-1]\n",
        "X_test = X_test.iloc[:,:-1]\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit_transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "print(X_train)\n",
        "print(X_valid)\n",
        "print(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turning target into one-hot format"
      ],
      "metadata": {
        "id": "G0Sp8OX_eLHT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeEww5qlm7U2"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the categorical labels\n",
        "encoder = OneHotEncoder(sparse_output=False)#, categories='auto')\n",
        "y_train_onehot = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_valid_onehot = encoder.transform(y_valid.values.reshape(-1, 1))\n",
        "y_test_onehot = encoder.transform(y_test.values.reshape(-1, 1))\n",
        "print(y_valid_onehot.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMVGSzwf40Zr"
      },
      "source": [
        "## MLP model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract metrics from confusion matrix\n",
        "def calculate_metrics(cm):\n",
        "    TP = cm[1, 1]\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
        "    mcc = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) \\\n",
        "        if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) != 0 else 0\n",
        "\n",
        "    return TP, TN, FP, FN, sensitivity, specificity, mcc\n",
        "\n",
        "# Define the improved MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, h1, h2, h3, output_size, dropout_rate=0.3):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, h1)\n",
        "        self.bn1 = nn.BatchNorm1d(h1)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.bn2 = nn.BatchNorm1d(h2)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.fc3 = nn.Linear(h2, h3)\n",
        "        self.bn3 = nn.BatchNorm1d(h3)\n",
        "        self.dropout3 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.fc4 = nn.Linear(h3, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Function to train and evaluate the model with early stopping\n",
        "def train_and_evaluate(X_train, y_train_onehot, X_valid, y_valid_onehot, X_test, y_test_onehot,\n",
        "                       num_epochs=200, lr=0.01, patience=10, weight_decay=1e-4, dropout_rate=0.3):\n",
        "    input_size = len(X_train[0])  # Input size\n",
        "    h1, h2, h3 = 80, 50, 20  # Reduced complexity\n",
        "    output_size = len(y_train_onehot[0])  # Output size for one-hot encoded labels\n",
        "\n",
        "    model = MLP(input_size, h1, h2, h3, output_size, dropout_rate=dropout_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    train_errors = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(torch.tensor(X_train, dtype=torch.float))\n",
        "        loss = criterion(outputs, torch.argmax(torch.tensor(y_train_onehot, dtype=torch.float), dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            valid_outputs = model(torch.tensor(X_valid, dtype=torch.float))\n",
        "            valid_loss = criterion(valid_outputs, torch.argmax(torch.tensor(y_valid_onehot, dtype=torch.float), dim=1))\n",
        "\n",
        "        # Early stopping\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_mlp_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        train_errors.append(loss.item())\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Valid Loss: {valid_loss.item()}')\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "        scheduler.step(valid_loss)\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load('best_mlp_model.pth'))\n",
        "\n",
        "    # Testing the model and calculating confusion matrices\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        train_outputs = model(torch.tensor(X_train, dtype=torch.float))\n",
        "        valid_outputs = model(torch.tensor(X_valid, dtype=torch.float))\n",
        "        test_outputs = model(torch.tensor(X_test, dtype=torch.float))\n",
        "\n",
        "    # Get predicted labels\n",
        "    train_preds = torch.argmax(train_outputs, dim=1).numpy()\n",
        "    valid_preds = torch.argmax(valid_outputs, dim=1).numpy()\n",
        "    test_preds = torch.argmax(test_outputs, dim=1).numpy()\n",
        "\n",
        "    # Calculate confusion matrices\n",
        "    train_cm = confusion_matrix(np.argmax(y_train_onehot, axis=1), train_preds)\n",
        "    valid_cm = confusion_matrix(np.argmax(y_valid_onehot, axis=1), valid_preds)\n",
        "    test_cm = confusion_matrix(np.argmax(y_test_onehot, axis=1), test_preds)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_metrics = calculate_metrics(train_cm)\n",
        "    valid_metrics = calculate_metrics(valid_cm)\n",
        "    test_metrics = calculate_metrics(test_cm)\n",
        "\n",
        "    return train_cm, valid_cm, test_cm, train_errors, train_outputs, valid_outputs, test_outputs, \\\n",
        "           train_metrics, valid_metrics, test_metrics\n",
        "\n",
        "# Main execution loop\n",
        "num_runs = 10\n",
        "train_cms, valid_cms, test_cms = [], [], []\n",
        "train_errors_list, train_outputs_list, valid_outputs_list, test_outputs_list = [], [], [], []\n",
        "train_metrics_list, valid_metrics_list, test_metrics_list = [], [], []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    print(f'Run {run + 1}/{num_runs}')\n",
        "    train_cm, valid_cm, test_cm, train_errors, train_outputs, valid_outputs, test_outputs, \\\n",
        "    train_metrics, valid_metrics, test_metrics = train_and_evaluate(\n",
        "        X_train, y_train_onehot, X_valid, y_valid_onehot, X_test, y_test_onehot,\n",
        "        num_epochs=200, lr=0.001, patience=10, weight_decay=1e-4, dropout_rate=0.3\n",
        "    )\n",
        "    train_cms.append(train_cm)\n",
        "    valid_cms.append(valid_cm)\n",
        "    test_cms.append(test_cm)\n",
        "    train_errors_list.append(train_errors)\n",
        "    train_outputs_list.append(train_outputs)\n",
        "    valid_outputs_list.append(valid_outputs)\n",
        "    test_outputs_list.append(test_outputs)\n",
        "    train_metrics_list.append(train_metrics)\n",
        "    valid_metrics_list.append(valid_metrics)\n",
        "    test_metrics_list.append(test_metrics)\n",
        "\n",
        "# Find the run with the lowest final validation error\n",
        "best_run_idx = np.argmin([errors[-1] for errors in train_errors_list])\n",
        "best_train_errors = train_errors_list[best_run_idx]\n",
        "best_train_outputs = train_outputs_list[best_run_idx]\n",
        "best_valid_outputs = valid_outputs_list[best_run_idx]\n",
        "best_test_outputs = test_outputs_list[best_run_idx]\n",
        "\n",
        "# Plot confusion matrices, ROC curves, and display metrics (as in your original code)\n",
        "# Plotting functions\n",
        "def plot_confusion_matrix(cm_mean, cm_std, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))  # Create a new figure for each confusion matrix\n",
        "    plt.imshow(cm_mean, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(cm_mean))\n",
        "    plt.xticks(tick_marks, tick_marks, rotation=45)\n",
        "    plt.yticks(tick_marks, tick_marks)\n",
        "    for i in range(len(cm_mean)):\n",
        "        for j in range(len(cm_mean)):\n",
        "            plt.text(j, i, f'{int(cm_mean[i, j])}',\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm_mean[i, j] > cm_mean.max() / 2 else \"black\")\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Calculate average and standard deviation of confusion matrices\n",
        "def calculate_cm_stats(cms):\n",
        "    cms = np.array(cms)\n",
        "    cm_mean = np.mean(cms, axis=0)\n",
        "    cm_std = np.std(cms, axis=0)\n",
        "    return cm_mean, cm_std\n",
        "\n",
        "train_cm_mean, train_cm_std = calculate_cm_stats(train_cms)\n",
        "valid_cm_mean, valid_cm_std = calculate_cm_stats(valid_cms)\n",
        "test_cm_mean, test_cm_std = calculate_cm_stats(test_cms)\n",
        "\n",
        "# Save Confusion Matrices\n",
        "plot_confusion_matrix(train_cm_mean, train_cm_std, title='Confusion Matrix (Train)')\n",
        "plt.savefig('/content/MLP_train_conf_matrix.svg', format='svg')\n",
        "plt.close()\n",
        "\n",
        "plot_confusion_matrix(valid_cm_mean, valid_cm_std, title='Confusion Matrix (Valid)')\n",
        "plt.savefig('/content/MLP_valid_conf_matrix.svg', format='svg')\n",
        "plt.close()\n",
        "\n",
        "plot_confusion_matrix(test_cm_mean, test_cm_std, title='Confusion Matrix (Test)')\n",
        "plt.savefig('/content/MLP_test_conf_matrix.svg', format='svg')\n",
        "plt.close()\n",
        "\n",
        "# Save ROC Curves\n",
        "def plot_roc_curve(y_true, y_pred, title='ROC Curve'):\n",
        "    plt.figure(figsize=(10, 8))  # Create a new figure for each ROC curve\n",
        "    output_size = y_true.shape[1]\n",
        "    for i in range(output_size):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred.numpy()[:, i])\n",
        "        auc = roc_auc_score(y_true[:, i], y_pred.numpy()[:, i])\n",
        "        plt.plot(fpr, tpr, label=f'Class {i + 1} (AUC = {auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "\n",
        "plot_roc_curve(y_train_onehot, best_train_outputs, title='ROC Curve (Train)')\n",
        "plt.savefig('/content/MLP_train_roc.svg', format='svg')\n",
        "plt.close()\n",
        "\n",
        "plot_roc_curve(y_valid_onehot, best_valid_outputs, title='ROC Curve (Valid)')\n",
        "plt.savefig('/content/MLP_valid_roc.svg', format='svg')\n",
        "plt.close()\n",
        "\n",
        "plot_roc_curve(y_test_onehot, best_test_outputs, title='ROC Curve (Test)')\n",
        "plt.savefig('/content/MLP_test_roc.svg', format='svg')\n",
        "plt.close()\n",
        "\n",
        "# Extract and display the best metrics\n",
        "best_train_metrics = train_metrics_list[best_run_idx]\n",
        "best_valid_metrics = valid_metrics_list[best_run_idx]\n",
        "best_test_metrics = test_metrics_list[best_run_idx]\n",
        "print(f'Best Train Metrics (TP, TN, FP, FN, Sensitivity, Specificity, MCC): {best_train_metrics}')\n",
        "print(f'Best Valid Metrics (TP, TN, FP, FN, Sensitivity, Specificity, MCC): {best_valid_metrics}')\n",
        "print(f'Best Test Metrics (TP, TN, FP, FN, Sensitivity, Specificity, MCC): {best_test_metrics}')"
      ],
      "metadata": {
        "id": "a90V7sIW8MJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IORpVrBKnDEZ"
      },
      "source": [
        "\n",
        "## SVM model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of runs\n",
        "n_runs = 10\n",
        "\n",
        "# Initialize storage for results\n",
        "conf_matrices_train = []\n",
        "conf_matrices_valid = []\n",
        "conf_matrices_test = []\n",
        "roc_curves_train = []\n",
        "roc_curves_valid = []\n",
        "roc_curves_test = []\n",
        "auc_train = []\n",
        "auc_valid = []\n",
        "auc_test = []\n",
        "\n",
        "# Metrics storage\n",
        "tp_train, tn_train, fp_train, fn_train = [], [], [], []\n",
        "tp_valid, tn_valid, fp_valid, fn_valid = [], [], [], []\n",
        "tp_test, tn_test, fp_test, fn_test = [], [], [], []\n",
        "sensitivity_train, specificity_train, mcc_train = [], [], []\n",
        "sensitivity_valid, specificity_valid, mcc_valid = [], [], []\n",
        "sensitivity_test, specificity_test, mcc_test = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    # Initialize SVM classifier\n",
        "    svm_classifier = SVC(kernel='rbf', C=0.1, gamma='scale', probability=True)\n",
        "\n",
        "    # Train the SVM classifier\n",
        "    svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Save the model to a file\n",
        "    joblib.dump(svm_classifier, 'svm_classifier.joblib')\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_train = svm_classifier.predict(X_train)\n",
        "    y_pred_valid = svm_classifier.predict(X_valid)\n",
        "    y_pred_test = svm_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
        "    conf_matrix_valid = confusion_matrix(y_valid, y_pred_valid)\n",
        "    conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    conf_matrices_train.append(conf_matrix_train)\n",
        "    conf_matrices_valid.append(conf_matrix_valid)\n",
        "    conf_matrices_test.append(conf_matrix_test)\n",
        "\n",
        "    # Calculate TP, TN, FP, FN, Sensitivity, Specificity, and MCC for train set\n",
        "    tp = np.diag(conf_matrix_train)\n",
        "    fp = conf_matrix_train.sum(axis=0) - tp\n",
        "    fn = conf_matrix_train.sum(axis=1) - tp\n",
        "    tn = conf_matrix_train.sum() - (fp + fn + tp)\n",
        "    tp_train.append(tp.sum())\n",
        "    tn_train.append(tn.sum())\n",
        "    fp_train.append(fp.sum())\n",
        "    fn_train.append(fn.sum())\n",
        "    sensitivity_train.append(tp.sum() / (tp.sum() + fn.sum()))\n",
        "    specificity_train.append(tn.sum() / (tn.sum() + fp.sum()))\n",
        "    mcc_train.append(matthews_corrcoef(y_train, y_pred_train))\n",
        "\n",
        "    # Calculate TP, TN, FP, FN, Sensitivity, Specificity, and MCC for valid set\n",
        "    tp = np.diag(conf_matrix_valid)\n",
        "    fp = conf_matrix_valid.sum(axis=0) - tp\n",
        "    fn = conf_matrix_valid.sum(axis=1) - tp\n",
        "    tn = conf_matrix_valid.sum() - (fp + fn + tp)\n",
        "    tp_valid.append(tp.sum())\n",
        "    tn_valid.append(tn.sum())\n",
        "    fp_valid.append(fp.sum())\n",
        "    fn_valid.append(fn.sum())\n",
        "    sensitivity_valid.append(tp.sum() / (tp.sum() + fn.sum()))\n",
        "    specificity_valid.append(tn.sum() / (tn.sum() + fp.sum()))\n",
        "    mcc_valid.append(matthews_corrcoef(y_valid, y_pred_valid))\n",
        "\n",
        "    # Calculate TP, TN, FP, FN, Sensitivity, Specificity, and MCC for test set\n",
        "    tp = np.diag(conf_matrix_test)\n",
        "    fp = conf_matrix_test.sum(axis=0) - tp\n",
        "    fn = conf_matrix_test.sum(axis=1) - tp\n",
        "    tn = conf_matrix_test.sum() - (fp + fn + tp)\n",
        "    tp_test.append(tp.sum())\n",
        "    tn_test.append(tn.sum())\n",
        "    fp_test.append(fp.sum())\n",
        "    fn_test.append(fn.sum())\n",
        "    sensitivity_test.append(tp.sum() / (tp.sum() + fn.sum()))\n",
        "    specificity_test.append(tn.sum() / (tn.sum() + fp.sum()))\n",
        "    mcc_test.append(matthews_corrcoef(y_test, y_pred_test))\n",
        "\n",
        "    # Obtain predicted probabilities\n",
        "    train_probs = svm_classifier.decision_function(X_train)\n",
        "    valid_probs = svm_classifier.decision_function(X_valid)\n",
        "    test_probs = svm_classifier.decision_function(X_test)\n",
        "\n",
        "    # ROC curves for each class\n",
        "    n_classes = len(np.unique(y_train))\n",
        "    roc_curves_train.append([roc_curve((y_train == i).astype(int), train_probs[:, i]) for i in range(n_classes)])\n",
        "    roc_curves_valid.append([roc_curve((y_valid == i).astype(int), valid_probs[:, i]) for i in range(n_classes)])\n",
        "    roc_curves_test.append([roc_curve((y_test == i).astype(int), test_probs[:, i]) for i in range(n_classes)])\n",
        "\n",
        "    # AUC for each class\n",
        "    auc_train.append([roc_auc_score((y_train == i).astype(int), train_probs[:, i]) for i in range(n_classes)])\n",
        "    auc_valid.append([roc_auc_score((y_valid == i).astype(int), valid_probs[:, i]) for i in range(n_classes)])\n",
        "    auc_test.append([roc_auc_score((y_test == i).astype(int), test_probs[:, i]) for i in range(n_classes)])\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_conf_matrix(conf_matrices, filename, title):\n",
        "    plt.figure(figsize=(8, 6))  # Match the figure size used in the MLP code\n",
        "\n",
        "    # Calculate the mean and standard deviation of the confusion matrices\n",
        "    mean_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "    std_conf_matrix = np.std(conf_matrices, axis=0)\n",
        "\n",
        "    # Plotting the mean confusion matrix\n",
        "    plt.imshow(mean_conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title, fontsize=14)  # Match the font size used in the MLP code\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(mean_conf_matrix))\n",
        "    plt.xticks(tick_marks, tick_marks, rotation=45, fontsize=12)  # Match the font size for ticks\n",
        "    plt.yticks(tick_marks, tick_marks, fontsize=12)  # Match the font size for ticks\n",
        "\n",
        "    # Adding text annotations for each cell\n",
        "    for i in range(len(mean_conf_matrix)):\n",
        "        for j in range(len(mean_conf_matrix)):\n",
        "            plt.text(\n",
        "                j, i,\n",
        "                f'{int(mean_conf_matrix[i, j])}',\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if mean_conf_matrix[i, j] > mean_conf_matrix.max() / 2 else \"black\",\n",
        "                fontsize=12  # Match the font size for annotations\n",
        "            )\n",
        "\n",
        "    plt.ylabel('True Label', fontsize=14)  # Match the font size for y-label\n",
        "    plt.xlabel('Predicted Label', fontsize=14)  # Match the font size for x-label\n",
        "    plt.tight_layout()  # Ensure proper spacing\n",
        "    plt.savefig(filename, format='svg')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(roc_curve_data, auc_data, filename):  # , title):\n",
        "    plt.figure(figsize=(10, 8))  # Match the figure size used in the MLP code\n",
        "\n",
        "    for class_idx in range(len(roc_curve_data[0])):\n",
        "        mean_fpr = np.mean([curve[class_idx][0] for curve in roc_curve_data], axis=0)\n",
        "        mean_tpr = np.mean([curve[class_idx][1] for curve in roc_curve_data], axis=0)\n",
        "        mean_auc = np.mean([auc[class_idx] for auc in auc_data])\n",
        "        plt.plot(mean_fpr, mean_tpr, label=f'Class {class_idx + 1} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
        "    plt.xlabel('False Positive Rate', fontsize=14)  # Match the font size for x-label\n",
        "    plt.ylabel('True Positive Rate', fontsize=14)  # Match the font size for y-label\n",
        "    plt.legend(loc='best', fontsize=12)  # Match the font size for the legend\n",
        "    plt.xticks(fontsize=12)  # Match the font size for ticks\n",
        "    plt.yticks(fontsize=12)  # Match the font size for ticks\n",
        "    plt.tight_layout()  # Ensure proper spacing\n",
        "    plt.savefig(filename, format='svg')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Plot and save confusion matrices\n",
        "plot_conf_matrix(conf_matrices_train, '/content/SVM_train_conf_matrix.svg', 'Confusion Matrix (Train)')\n",
        "plot_conf_matrix(conf_matrices_valid, '/content/SVM_valid_conf_matrix.svg', 'Confusion Matrix (Valid)')\n",
        "plot_conf_matrix(conf_matrices_test, '/content/SVM_test_conf_matrix.svg', 'Confusion Matrix (Test)')\n",
        "\n",
        "# Plot and save ROC curves\n",
        "plot_roc_curve(roc_curves_train, auc_train, '/content/SVM_train_roc_curve.svg')  # , 'Train ROC Curve')\n",
        "plot_roc_curve(roc_curves_valid, auc_valid, '/content/SVM_valid_roc_curve.svg')  # , 'Valid ROC Curve')\n",
        "plot_roc_curve(roc_curves_test, auc_test, '/content/SVM_test_roc_curve.svg')  # , 'Test ROC Curve')\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Train - TP: {np.mean(tp_train):.2f}, TN: {np.mean(tn_train):.2f}, FP: {np.mean(fp_train):.2f}, FN: {np.mean(fn_train):.2f}\")\n",
        "print(f\"Train - Sensitivity: {np.mean(sensitivity_train):.2f}, Specificity: {np.mean(specificity_train):.2f}, MCC: {np.mean(mcc_train):.2f}\")\n",
        "print(f\"Valid - TP: {np.mean(tp_valid):.2f}, TN: {np.mean(tn_valid):.2f}, FP: {np.mean(fp_valid):.2f}, FN: {np.mean(fn_valid):.2f}\")\n",
        "print(f\"Valid - Sensitivity: {np.mean(sensitivity_valid):.2f}, Specificity: {np.mean(specificity_valid):.2f}, MCC: {np.mean(mcc_valid):.2f}\")\n",
        "print(f\"Test - TP: {np.mean(tp_test):.2f}, TN: {np.mean(tn_test):.2f}, FP: {np.mean(fp_test):.2f}, FN: {np.mean(fn_test):.2f}\")\n",
        "print(f\"Test - Sensitivity: {np.mean(sensitivity_test):.2f}, Specificity: {np.mean(specificity_test):.2f}, MCC: {np.mean(mcc_test):.2f}\")"
      ],
      "metadata": {
        "id": "MOUd3lqj_dZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}